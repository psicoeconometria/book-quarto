[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Your title",
    "section": "",
    "text": "Abstract\nThis is a Quarto book template for scientific article.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\nKey-words:\nHow cite this template:",
    "crumbs": [
      "Abstract"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "De acordo com Munafò et al. (2017), a pesquisa científica atual enfrenta vários desafios. Problemas como o pequeno tamanho da amostra, pequenos tamanhos de efeito, p-hacking e HARKing (viés positivo de publicação), conflitos de interesse e a competição entre cientistas que trabalham isoladamente sem combinar seus esforços, têm sido apontados como catalizadores do que se convencionou chamar de “crise de reprodutibilidade” na ciência (Baker 2016; Munafò et al. 2017).\nPesquisas apontam que mais de 70% de pesquisadores que tentaram, falharam em reproduzir os experimentos de outros cientistas, e mais da metade falhou em reproduzir seus próprios experimentos (Baker, 2016), com estimativa de que 85% dos esforços de pesquisas estejam sendo desperdiçados (Munafò et al. 2017), gerando custos econômicos bilionários (Freedman, Cockburn, and Simcoe 2015). A despeito daqueles que advogam que não existe essa tal “crise de reprodutibilidade” (Bernard 2023; Fanelli 2018; Protzko et al. 2023), a grande maioria da comunidade científica concorda com sua existência e defende a melhoria da transparência, reprodutibilidade e eficiência na ciência (Baker, 2016).\nNesse contexto, o movimento da Ciência Aberta (CA) tem ganhado notoriedade e mudado a percepção sobre o cenário científico global (Crüwell et al. 2019). Ele busca tornar o conhecimento científico mais acessível, transparente e colaborativo. Se apresenta como uma coleção de práticas de democratização do conhecimento e ruptura com o formato único de divulgação do conhecimento científico (Crüwell et al. 2019; Heinz and Miranda 2024; Munafò et al. 2017). Ele surge do embate entre aqueles que buscam compartilhar o conhecimento e aqueles que defendem mecanismos de apropriação privada para a produção científica (Heinz and Miranda 2024).\nA CA é um termo múltiplo e genérico (Vicente-Saez and Martinez-Fuentes 2018), que representa diversas interpretações, e é considerada um novo modelo de divulgação e produção de resultados científicos por meio do acesso livre e irrestrito ao conhecimento (Heinz and Miranda 2024). A CA não é apenas um conceito, mas uma prática multifacetada que influencia o ciclo de vida da pesquisa, desde a concepção até a disseminação dos resultados (Silva and Silveira 2019). Existem pelo menos cinco escolas de pensamento dentro da CA. Estas escolas abrangem desde a arquitetura tecnológica necessária para suportar a ciência até a inclusão do público geral na criação de conhecimento, passando pela medição do impacto alternativo, acesso ao conhecimento como um direito humano, e a pesquisa colaborativa como inovação aberta (Silva and Silveira 2019). A taxonomia proposta pela FOSTER (Facilitate Open Science Training for Eurpean Research)(https://www.fosteropenscience.eu/foster-taxonomy/open-workflow-tools), e sua releitura revisada e ampliada para o contexto latino americano por Silveira et al. (2023), tendo em vista as recomendações da UNESCO (2021), nos dá uma dimensão da complexidade do assunto (vide ilustração em: https://doi.org/10.5281/zenodo.7836884). Existem vários argumentos que sustentam a importância da CA (Heinz and Miranda 2024). Primeiramente, a CA pode trazer benefícios sociais significativos, pois contribui para o avanço do conhecimento, a inovação, a educação, a transparência e a participação cidadã. Além disso, a CA pode trazer benefícios científicos ao aumentar a qualidade, a reprodutibilidade, a eficiência e o impacto da pesquisa científica. Ela também facilita a colaboração, a comunicação e a interdisciplinaridade entre os pesquisadores. Por fim, a CA pode trazer benefícios éticos ao promover a integridade, a responsabilidade, a equidade e a diversidade na ciência, além de respeitar os direitos dos autores, dos participantes e da sociedade como um todo. Esses argumentos são fundamentais para legitimar a CA e destacar sua importância no mundo atual (Heinz and Miranda 2024), principalmente, como potencial transformador para reduzir desigualdades existentes em tecnologias de informação e comunicação – reduzir exclusões digitais, tecnológicas e de conhecimento –, e acelerar o progresso rumo à implementação da Agenda 2030 e realização dos Objetivos de Desenvolvimento Sustentável (UNESCO 2021). O movimento da CA no Brasil está em uma fase transitória (Rezende and Falgueras 2020) – ainda consolidando o acesso aberto – com o governo desempenhando um papel crucial nesse processo. O Brasil tem ganhado destaque por sua abordagem única na implementação da CA. Esta abordagem é moldada por marcos regulatórios que se estendem desde o governo até as instituições e agências de financiamento. Os regulamentos brasileiros, particularmente aqueles que promovem a abertura de dados governamentais, têm um impacto direto na prática científica. Eles incentivam a transparência e facilitam o acesso a dados científicos originados de instituições públicas (Rezende and Falgueras 2020). A trajetória brasileira rumo à CA inicia com a abertura de dados na esfera governamental entre 2009 e 2016, evoluindo para a criação de um grupo de trabalho em 2017 pelo Ministério da Ciência, Tecnologia, Inovações e Comunicações (MCTIC) para desenvolver uma política nacional para a CA. Este esforço concentrou ênfase no reconhecimento dos dados de pesquisa como ativos de desenvolvimento científico, econômico e social, buscando facilitar seu acesso, compartilhamento e reutilização (Rezende and Falgueras 2020). Talvez por esse motivo, as políticas institucionais brasileiras revelam um cenário ainda muito influenciado pela “via verde” do movimento de acesso aberto, caracterizado pelo depósito de dados em repositórios digitais abertos, e que o comprometimento efetivo do Brasil com a CA ainda é incipiente. As regulamentações atuais favorecem principalmente o acesso aberto, sem abordar de maneira abrangente outros aspectos da CA (Rezende and Falgueras 2020). O Brasil é um dos líderes mundiais no fornecimento de acesso universal às suas pesquisas e estudos (Neto, Willinsky, and Alperin 2016), com crescimento estável de sua produção científica disponível em acesso aberto, principalmente, as áreas de Agricultura e Ciência & Tecnologia (Caballero-Rivero, Sánchez-Tarragó, and dos Santos 2019). Em termos de pesquisa acadêmica sobre o tema no Brasil, os estudos são precoces e concentrados na área de Ciência da Informação (Albano, Pedroso, and Caetano 2023). A despeito da maturidade da CA no Brasil, a importância do tema – materializada na quantidade de produção acadêmica – tem aumentado vertiginosamente (Albano, Pedroso, and Caetano 2023), e a dispersão de autores e respectivas instituições que publicam sobre o assunto, parece ser a situação predominante. Apesar de importantes atores nacionais, tais como CAPES, CNPq e Scielo, defenderem o crescimento de iniciativas de CA (Mendes-Da-Silva 2023), o assunto no Brasil parece estar circunscrito em iniciativas de importantes periódicos nacionais sobre dados aberto, capitaneados pelas orientações da Scielo. Não foi encontrada nenhuma pesquisa empírica, sobre a prática da CA no Brasil. Por prática de CA entende-se a perspectiva micro da CA, relacionadas com as terminologias e conhecimento em torno do fluxo de trabalho do gerador de conhecimento científico aberto (vide ilustração em: https://doi.org/10.5281/zenodo.10835001), ou seja, o cientista em gestão que se propõe tornar sua pesquisa transparente, reprodutível e replicável. Exclui-se a perspectiva macro, relacionadas com as ramificações conceituais da CA concernentes às políticas públicas, infraestrutura, envolvimento aberto de atores sociais e diálogo aberto com outros sistemas de conhecimento (vide ilustração em: https://doi.org/10.5281/zenodo.10835001). Essa última perspectiva está fora do escopo do projeto, que se concentra em algumas das dimensões da perspectiva micro, particularmente, as ferramentas disponíveis para compilação dos produtos científicos que integram a publicação científica (UNESCO 2021). Apesar de uma verossímil expectativa desabonadora, tendo em vista a contexto da CA no Brasil, o diagnóstico da situação da prática da CA se mostra importante, per si, pois: 1) ajuda a compreender a natureza exata do problema, suas causas, efeitos e riscos; 2) auxilia a alocação eficiente de recursos pelos atores envolvidos (e.g., os programas de pós-graduação podem direcionar os recursos para onde eles são mais necessários e onde terão o maior impacto; 3) orienta indicadores de desempenho e metas realistas, o que facilita a avaliação do progresso e a eficácia das ações tomadas; 4) permite que os atores envolvidos aprendam com os problemas enfrentados, adaptando-se e melhorando suas estratégias e processos para o futuro; e 5) torna possível desenvolver soluções ou intervenções que sejam diretamente direcionadas ao problema em questão, aumentando as chances de sucesso. Sobre esse último ponto, até para aqueles que não reconhecem a “crise de reprodutibilidade” na ciência (Bernard 2023), a comunidade científica e atores importantes do cenário advogam que a solução inclui educar os estudantes e pesquisadores desde cedo em todas as questões da CA (Baker et al., 2023; Bezjak et al., 2018; Chopik et al., 2018; Crüwell et al., 2019; Dogucu & Çetinkaya-Rundel, 2022; Janz, 2015; McAleer et al., 2022; Munafò et al., 2017; Toelch & Ostwald, 2018). A referida crise não deriva de má conduta científica, mas principalmente da confusão entre replicar conclusões, replicar resultados, falta de educação em estatística, lógica científica, método científico, alfabetização de dados, etc. Para combater essas questões é necessário investir em educação e disseminação de boas práticas de investigação para uma mudança de cultura (Baker et al., 2023; Bezjak et al., 2018; Chopik et al., 2018; Crüwell et al., 2019; Dogucu & Çetinkaya-Rundel, 2022; Heinz & Miranda, 2024; Janz, 2015; McAleer et al., 2022; Munafò et al., 2017; Toelch & Ostwald, 2018).\nInvestir em recursos humanos, treinamento, educação, alfabetização digital, capacitação sistemática e contínua, e fomentar uma cultura científica de CA, têm sido apresentadas como algumas das principais medidas simultâneas para superar o cenário atual (Committee on Reproducibility and Replicability in Science et al. 2019; European Commission. Directorate General for Research and Innovation. 2017; UNESCO 2021).\nA proposta do presente projeto de pesquisa pode contribuir para a literatura da CA no Brasil, pois pretende perseguir dois objetivos concomitantes: 1) diagnosticar sua prática junto aos pesquisadores brasileiros; e 2) promover o desenvolvimento de uma intervenção educacional sobre a prática (workflow) e principais ferramentas para compilação dos produtos científicos que integram uma publicação científica aberta. Sobre o primeiro objetivo, os detalhes serão apresentados num pré-registro (vantveer2016?) que disponibilizaremos após a aprovação do projeto, seguindo as boas práticas de CA (Gilroy and Kaplan 2019; kathawalla2021?; klein2018?), no entanto, em termos de delineamento pode-se adiantar que a partir da população-alvo, faremos a tradução e adaptação transcultural (behr2016?) do instrumento de medida de Ferguson et al. (2023), que pelas nossas pesquisas preliminares, se mostrou a pesquisa mais ampla e confiável sobre atitudes, usabilidade e percepção sobre as práticas de CA junto a pesquisadores. Em português não existe nenhum instrumento de medida válido e confiável sobre esses construtos, e esse objetivo per si, pode ser considerado um produto científico. Em posse do instrumento de medida válido e confiável, seguindo as melhores práticas da literatura psicométrica (bandalos2018?; cohen2022?; furr2021?; rogers2024?; rogers2022?; urbina2014?) e diretrizes da pesquisa original (ferguson2023?) para sua replicação, em outra amostra da população-alvo, diagnosticaremos o panorama geral da prática de CA no Brasil. Essa segunda amostra será coletada em dois momentos: i) antes da intervenção (pré-teste) e ii) depois da intervenção (pós-teste). Coletaremos informações de indivíduos que realizarão (grupo experimental) e não realização (grupo controle) o treinamento em práticas de CA (tratamento/intervenção). Os participantes serão convidados aleatoriamente – via e-mail e comunicação durante a intervenção para preenchimento de um questionário on-line – para cada um dos grupos. Não teremos a pretensão de escapar do viés de autoseleção e abandono, devido a característica do delineamento. A amostra que buscará estabelecer uma linha de base (pré-teste) para o treinamento, pode ser utilizada para reflexões sobre o panorama geral da prática de CA no Brasil. No entanto, com a implementação da intervenção e posterior aplicação do pós-teste, poderemos comparar os resultados dentro de cada grupo e medida repetida para avaliar a eficácia do treinamento no quase-experimento. Utilizaremos as técnicas estatísticas adequadas para a design metodológico da pesquisa, circunscritas no arcabouço da Modelagem de Equações Estruturais (hair2019book?; hoyle2023?; kline2023?), e seguiremos de perto algumas propostas de workflow para a reprodutibilidade, replicabilidade e transparência da pesquisas (mang2023?; peikert2021?; peikert2021a?; vanlissa2021?), conforme preconizadas nas boas práticas de CA (Gilroy and Kaplan 2019; kathawalla2021?; klein2018?). Diferente do primeiro objetivo, que no presente projeto foi apenas esboçado, o segundo objetivo, quando do começo do projeto, espera-se que esteja com escopo concluído nos moldes recomendados pela literatura de CA (Dogucu and Çetinkaya-Rundel 2022). Isso porque o conteúdo do curso faz parte do dia a dia dos proponentes desse projeto. As ferramentas que serão ministradas no curso (OSF, Zotero, Git/Github, Zenodo, RStudio, Quarto, Docker, etc.) fazem parte do workflow de trabalho dos proponentes, e o curso, está sendo concebido enquanto projeto de extensão universitária (https://phdpablo.github.io/curso-open-science/), e será ministrado pelo menos uma vez como piloto no ano corrente. Cremos que adiantar esse piloto nos ajudará i) avaliar se a intervenção pode ser implementada como planejado no contexto real; ii) identificar e corrigir quaisquer problemas ou falhas na concepção da intervenção antes de realizar o estudo; iii) ajustar os materiais, recursos, métodos e procedimentos operacionais do treinamento para melhorar a eficácia e a eficiência; iv) familiarizar com o processo e resolver quaisquer dificuldades operacionais; v) garantir que todos os envolvidos compreendam e sigam o protocolo de pesquisa corretamente (janghorban2014?), reduzindo a variabilidade na implementação; v) identificar potenciais problemas éticos; e vi) definir expectativas realistas sobre os resultados e o impacto da intervenção, tanto para os pesquisadores quanto para os participantes (kezar2000?; thabane2010?). Esse quase-experimento como uma pesquisa-ação, em um contexto universitário, integra de forma profícua as atividades de ensino, pesquisa e extensão universitária (estevescampos2020?), promovendo a indissociabilidade, interdisciplinaridade, multidimensionalidade, integração e articulação dessa tríade, quase sempre inexistente em grande parte dos projetos de pesquisa nas universidade brasileiras (farias2010?), porém de suma importância (goncalves2015?). Nesse sentido, esse projeto de pesquisa se associa à um projeto de ensino por proporcionar uma experiência de aprendizagem integrada para os envolvidos na academia, desenvolvendo habilidades e competências essenciais (moita2009?). Como projeto de extensão, ele transcende os limites da universidade, aplicando o conhecimento gerado para beneficiar a comunidade mais ampla e promover mudanças sociais positivas (rays2012?), principalmente, através da comunicação científica (targino2000?).\n\n\n\n\nAlbano, Cláudio Sonáglio, Paula de Oliveira Pedroso, and Doriedson Oliveira Caetano. 2023. “Ciência Aberta: Um Panorama Sobre as Publicações No Cenário Brasileiro.” Saber Científico 12 (1): 1–12.\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nBernard, Christophe. 2023. “Stop Reproducing the Reproducibility Crisis.” Eneuro 10 (2): ENEURO.0032–23.2023. https://doi.org/10.1523/ENEURO.0032-23.2023.\n\n\nCaballero-Rivero, Alejandro, Nancy Sánchez-Tarragó, and Raimundo Nonato Macedo dos Santos. 2019. “Práticas de Ciência Aberta Da Comunidade Acadêmica Brasileira: Estudo a Partir Da Produção Científica.” Transinformação 31 (November): e190029. https://doi.org/10.1590/2318-0889201931e190029.\n\n\nCommittee on Reproducibility and Replicability in Science, Board on Behavioral, Cognitive, and Sensory Sciences, Committee on National Statistics, Division of Behavioral and Social Sciences and Education, Nuclear and Radiation Studies Board, Division on Earth and Life Studies, Board on Mathematical Sciences and Analytics, et al. 2019. Reproducibility and Replicability in Science. Washington, D.C.: National Academies Press. https://doi.org/10.17226/25303.\n\n\nCrüwell, Sophia, Johnny Van Doorn, Alexander Etz, Matthew C. Makel, Hannah Moshontz, Jesse C. Niebaum, Amy Orben, Sam Parsons, and Michael Schulte-Mecklenbeck. 2019. “Seven Easy Steps to Open Science: An Annotated Reading List.” Zeitschrift für Psychologie 227 (4): 237–48. https://doi.org/10.1027/2151-2604/a000387.\n\n\nDogucu, Mine, and Mine Çetinkaya-Rundel. 2022. “Tools and Recommendations for Reproducible Teaching.” Journal of Statistics and Data Science Education 30 (3): 251–60. https://doi.org/10.1080/26939169.2022.2138645.\n\n\nEuropean Commission. Directorate General for Research and Innovation. 2017. Providing Researchers with the Skills and Competencies They Need to Practise Open Science. LU: Publications Office.\n\n\nFanelli, Daniele. 2018. “Is Science Really Facing a Reproducibility Crisis, and Do We Need It To?” Proceedings of the National Academy of Sciences 115 (11): 2628–31. https://doi.org/10.1073/pnas.1708272114.\n\n\nFreedman, Leonard P., Iain M. Cockburn, and Timothy S. Simcoe. 2015. “The Economics of Reproducibility in Preclinical Research.” PLOS Biology 13 (6): e1002165. https://doi.org/10.1371/journal.pbio.1002165.\n\n\nGilroy, Shawn P., and Brent A. Kaplan. 2019. “Furthering Open Science in Behavior Analysis: An Introduction and Tutorial for Using GitHub in Research.” Perspectives on Behavior Science 42 (3): 565–81. https://doi.org/10.1007/s40614-019-00202-5.\n\n\nHeinz, Michele, and Miranda Miranda. 2024. “Ciência Aberta: Argumentos e Desafios Para Sua Legitimação Científica.” Em Questão 30. https://doi.org/10.1590/1808-5245.30.135618.\n\n\nMendes-Da-Silva, Wesley. 2023. “What Lectures and Research in Business Management Need to Know About Open Science.” Revista de Administração de Empresas 63 (4): e0000–0033. https://doi.org/10.1590/s0034-759020230408x.\n\n\nMunafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S. Button, Christopher D. Chambers, Nathalie Percie Du Sert, Uri Simonsohn, Eric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017. “A Manifesto for Reproducible Science.” Nature Human Behaviour 1 (1): 0021. https://doi.org/10.1038/s41562-016-0021.\n\n\nNeto, Silvio Carvalho, John Willinsky, and Juan Pablo Alperin. 2016. “Measuring, Rating, Supporting, and Strengthening Open Access Scholarly Publishing in Brazil.” Education Policy Analysis Archives 24 (May): 54–54. https://doi.org/10.14507/epaa.24.2391.\n\n\nProtzko, John, Jon Krosnick, Leif Nelson, Brian A. Nosek, Jordan Axt, Matt Berent, Nicholas Buttrick, et al. 2023. “High Replicability of Newly Discovered Social-Behavioural Findings Is Achievable.” Nature Human Behaviour, November. https://doi.org/10.1038/s41562-023-01749-9.\n\n\nRezende, Laura Vilela Rodrigues, and Ernest Abadal Falgueras. 2020. “Estado Da Arte Dos Marcos Regulatórios Brasileiros Rumo à Ciência Aberta.” Encontros Bibli: Revista Eletrônica de Biblioteconomia e Ciência Da Informação 25 (September): 01–25. https://doi.org/10.5007/1518-2924.2020.e71370.\n\n\nSilva, Fabiano Couto Corrêa Da, and Lúcia Da Silveira. 2019. “O Ecossistema Da Ciência Aberta.” Transinformação 31: e190001. https://doi.org/10.1590/2318-0889201931e190001.\n\n\nUNESCO. 2021. “UNESCO Recommendation on Open Science.” UNESCO. https://doi.org/10.54677/MNMH8546.\n\n\nVicente-Saez, Ruben, and Clara Martinez-Fuentes. 2018. “Open Science Now: A Systematic Literature Review for an Integrated Definition.” Journal of Business Research 88 (July): 428–36. https://doi.org/10.1016/j.jbusres.2017.12.043.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-background.html",
    "href": "02-background.html",
    "title": "2  Background",
    "section": "",
    "text": "In summary, this article has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "04-results.html",
    "href": "04-results.html",
    "title": "4  Results",
    "section": "",
    "text": "4.1 Plot Output\nYou can also embed plots, for example:\nCode\nlibrary(ggplot2)\ndat &lt;- data.frame(cond = rep(c(\"A\", \"B\"), each=10),\n                  xvar = 1:20 + rnorm(20,sd=3),\n                  yvar = 1:20 + rnorm(20,sd=3))\n\nggplot(dat, aes(x=xvar, y=yvar)) +\n    geom_point(shape=1) + \n    geom_smooth() \n\n\n\n\n\n\n\n\nFigure 4.1: Pressure\nNote that the code-fold: true parameter was added to the code chunk to hide the code by default (click “Code” above the plot to see the code).\nThe use of the label and fig-cap options make this a cross-referenceable figure (see Figure 4.1).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#tables",
    "href": "04-results.html#tables",
    "title": "4  Results",
    "section": "4.2 Tables",
    "text": "4.2 Tables\nUse the knitr::kable() function to print tables as HTML:\n\nknitr::kable(head(ggplot2::diamonds))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncarat\ncut\ncolor\nclarity\ndepth\ntable\nprice\nx\ny\nz\n\n\n\n\n0.23\nIdeal\nE\nSI2\n61.5\n55\n326\n3.95\n3.98\n2.43\n\n\n0.21\nPremium\nE\nSI1\n59.8\n61\n326\n3.89\n3.84\n2.31\n\n\n0.23\nGood\nE\nVS1\n56.9\n65\n327\n4.05\n4.07\n2.31\n\n\n0.29\nPremium\nI\nVS2\n62.4\n58\n334\n4.20\n4.23\n2.63\n\n\n0.31\nGood\nJ\nSI2\n63.3\n58\n335\n4.34\n4.35\n2.75\n\n\n0.24\nVery Good\nJ\nVVS2\n62.8\n57\n336\n3.94\n3.96\n2.48",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#latex-math",
    "href": "04-results.html#latex-math",
    "title": "4  Results",
    "section": "4.3 LaTeX Math",
    "text": "4.3 LaTeX Math\nYou can also include LaTeX math:\n\\[\nP\\left(A=2\\middle|\\frac{A^2}{B}&gt;4\\right)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Albano, Cláudio Sonáglio, Paula de Oliveira Pedroso, and Doriedson\nOliveira Caetano. 2023. “Ciência Aberta:\nUm Panorama Sobre as Publicações No Cenário Brasileiro.” Saber\nCientífico 12 (1): 1–12.\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the\nLid on Reproducibility.”\nNature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nBernard, Christophe. 2023. “Stop Reproducing the\nReproducibility Crisis.” Eneuro 10 (2):\nENEURO.0032–23.2023. https://doi.org/10.1523/ENEURO.0032-23.2023.\n\n\nCaballero-Rivero, Alejandro, Nancy Sánchez-Tarragó, and Raimundo Nonato\nMacedo dos Santos. 2019. “Práticas de Ciência Aberta Da\nComunidade Acadêmica Brasileira: Estudo a Partir Da\nProdução Científica.”\nTransinformação 31 (November):\ne190029. https://doi.org/10.1590/2318-0889201931e190029.\n\n\nCommittee on Reproducibility and Replicability in Science, Board on\nBehavioral, Cognitive, and Sensory Sciences, Committee on National\nStatistics, Division of Behavioral and Social Sciences and Education,\nNuclear and Radiation Studies Board, Division on Earth and Life Studies,\nBoard on Mathematical Sciences and Analytics, et al. 2019.\nReproducibility and Replicability in\nScience. Washington, D.C.: National Academies Press.\nhttps://doi.org/10.17226/25303.\n\n\nCrüwell, Sophia, Johnny Van Doorn, Alexander Etz, Matthew C. Makel,\nHannah Moshontz, Jesse C. Niebaum, Amy Orben, Sam Parsons, and Michael\nSchulte-Mecklenbeck. 2019. “Seven Easy Steps to\nOpen Science: An Annotated Reading\nList.” Zeitschrift für Psychologie\n227 (4): 237–48. https://doi.org/10.1027/2151-2604/a000387.\n\n\nDogucu, Mine, and Mine Çetinkaya-Rundel. 2022. “Tools and\nRecommendations for Reproducible\nTeaching.” Journal of Statistics and Data Science\nEducation 30 (3): 251–60. https://doi.org/10.1080/26939169.2022.2138645.\n\n\nEuropean Commission. Directorate General for Research and Innovation.\n2017. Providing Researchers with the\nSkills and Competencies They Need to\nPractise Open Science. LU: Publications Office.\n\n\nFanelli, Daniele. 2018. “Is Science Really Facing a\nReproducibility Crisis, and Do We Need It\nTo?” Proceedings of the National Academy of\nSciences 115 (11): 2628–31. https://doi.org/10.1073/pnas.1708272114.\n\n\nFreedman, Leonard P., Iain M. Cockburn, and Timothy S. Simcoe. 2015.\n“The Economics of Reproducibility in\nPreclinical Research.” PLOS Biology 13 (6):\ne1002165. https://doi.org/10.1371/journal.pbio.1002165.\n\n\nGilroy, Shawn P., and Brent A. Kaplan. 2019. “Furthering\nOpen Science in Behavior Analysis: An\nIntroduction and Tutorial for Using\nGitHub in Research.” Perspectives on\nBehavior Science 42 (3): 565–81. https://doi.org/10.1007/s40614-019-00202-5.\n\n\nHeinz, Michele, and Miranda Miranda. 2024. “Ciência\nAberta: Argumentos e Desafios Para Sua Legitimação Científica.” Em\nQuestão 30. https://doi.org/10.1590/1808-5245.30.135618.\n\n\nMendes-Da-Silva, Wesley. 2023. “What Lectures and\nResearch in Business Management Need to\nKnow About Open Science.” Revista de\nAdministração de Empresas 63 (4):\ne0000–0033. https://doi.org/10.1590/s0034-759020230408x.\n\n\nMunafò, Marcus R., Brian A. Nosek, Dorothy V. M. Bishop, Katherine S.\nButton, Christopher D. Chambers, Nathalie Percie Du Sert, Uri Simonsohn,\nEric-Jan Wagenmakers, Jennifer J. Ware, and John P. A. Ioannidis. 2017.\n“A Manifesto for Reproducible\nScience.” Nature Human Behaviour 1 (1): 0021. https://doi.org/10.1038/s41562-016-0021.\n\n\nNeto, Silvio Carvalho, John Willinsky, and Juan Pablo Alperin. 2016.\n“Measuring, Rating, Supporting, and\nStrengthening Open Access Scholarly Publishing in\nBrazil.” Education Policy Analysis Archives\n24 (May): 54–54. https://doi.org/10.14507/epaa.24.2391.\n\n\nProtzko, John, Jon Krosnick, Leif Nelson, Brian A. Nosek, Jordan Axt,\nMatt Berent, Nicholas Buttrick, et al. 2023. “High\nReplicability of Newly Discovered Social-Behavioural\nFindings Is Achievable.” Nature Human Behaviour,\nNovember. https://doi.org/10.1038/s41562-023-01749-9.\n\n\nRezende, Laura Vilela Rodrigues, and Ernest Abadal Falgueras. 2020.\n“Estado Da Arte Dos Marcos Regulatórios Brasileiros Rumo à Ciência Aberta.” Encontros Bibli:\nRevista Eletrônica de Biblioteconomia e\nCiência Da Informação 25\n(September): 01–25. https://doi.org/10.5007/1518-2924.2020.e71370.\n\n\nSilva, Fabiano Couto Corrêa Da, and Lúcia Da Silveira. 2019. “O\nEcossistema Da Ciência\nAberta.”\nTransinformação 31: e190001. https://doi.org/10.1590/2318-0889201931e190001.\n\n\nUNESCO. 2021. “UNESCO Recommendation on Open\nScience.” UNESCO. https://doi.org/10.54677/MNMH8546.\n\n\nVicente-Saez, Ruben, and Clara Martinez-Fuentes. 2018. “Open\nScience Now: A Systematic Literature Review\nfor an Integrated Definition.” Journal of\nBusiness Research 88 (July): 428–36. https://doi.org/10.1016/j.jbusres.2017.12.043.",
    "crumbs": [
      "References"
    ]
  }
]